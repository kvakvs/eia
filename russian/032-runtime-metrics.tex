%\chapter{Runtime Metrics}
\chapter{Метрики времени выполнения}
\label{chap:runtime-metrics}

%One of the best selling points of the Erlang VM for production use is how transparent it can be for all kinds of introspection, debugging, profiling, and analysis at run time.
Одной из наиболее хорошо продаваемых характеристик виртуальной машины Erlang для производственного использования является то, как она прозрачна для всех способов диагностики, отладки, профилирования и анализа на ходу во время выполнения.

%The advantage of having these runtime metrics accessible programmatically is that building tools relying on them is easy, and building automation for some tasks or watchdogs is equally simple\footnote{Making sure your automated processes don't run away and go overboard with whatever corrective actions they take is more complex}. Then, in times of need, it's also possible to bypass the tools and go direct to the VM for information.
Преимуществом наличия таких метрик, доступных программно, является то, что построение как инструментов так и скриптов для автоматизации, которые на них основаны оказывается вполне простым\footnote{Гораздо сложнее гарантировать, что автоматизированные процессы не переборщили с исправительными мерами.}. Затем, когда понадобится, возможно избавиться от инструментов и обратиться прямо к виртуальной машине и запросить нужную информацию.

%A practical approach to growing a system and keeping it healthy in production is to make sure all angles are observable: in the large, and in the small. There's no generic recipe to tell in advance what is going to be normal or not. You want to keep a lot of data and to look at it from time to time to form an idea about what your system looks like under normal circumstances. The day something goes awry, you will have all these angles you've grown to know, and it will be simpler to find what is off and needs fixing.
Практическим подходом к росту системы и поддержанию её в хорошем здоровье на производственном (\emph{production}) сервере --- это убедиться, что систему можно наблюдать со всех углов, как в большом масштабе, так и все мельчайшие её детали. Нет общего рецепта, который сразу скажет вам является ли тот или иной показатель нормальным или аварийным. Вам следует сохранять множество данных и время от времени смотреть на них, чтобы сформировать своё мнение о том, как система выглядит в обычных условиях. В тот день, когда что-то пойдёт не так, у вас будет опыт всех этих точек зрения, к которым вы привыкли, и вам будет легче обнаружить, что вышло из-под контроля и требует ремонта.

%For this chapter (and most of those that follow), most of the concepts or features to be shown are accessible through code in the standard library, part of the regular OTP distribution. 
Для этой главы (и многих глав после этой), многие показанные концепции или возможности доступны прямо из вашего кода с помощью стандартных библиотек, которые являются частью каждого дистрибутива OTP.

%However, these features aren't all in one place, and can make it too easy to shoot yourself in the foot within a production system. They also tend to be closer to building blocks than usable tools.
Однако эти возможности не сложены в одном месте, и могут очень облегчить задачу простреливания себе ноги на производственной системе. Также они стремятся быть скорее строительными блоками, чем готовыми к использованию инструментами.

%Therefore, to make the text lighter and to be more usable, common operations have been regrouped in the \otpapp{recon}\footnote{\href{http://ferd.github.io/recon/}{http://ferd.github.io/recon/}} library, and are generally production-safe.
Таким образом, чтобы сделать текст книги легче для чтения и удобнее, я сгруппировал общие операции в библиотеке \otpapp{recon}\footnote{\href{http://ferd.github.io/recon/}{http://ferd.github.io/recon/}} и они в целом безопасны для использования на производственной системе.

%\section{Global View}
\section{Вид сверху}
\label{sec:global-view}

%For a view of the VM in the large, it's useful to track statistics and metrics general to the VM, regardless of the code running on it. Moreover, you should aim for a solution that allows long-term views of each metric — some problems show up as a very long accumulation over weeks that couldn't be detected over small time windows.
Для осмотра состояния виртуальной машины в большом масштабе полезно собирать статистику и метрики общие для виртуальной машины, независимо от того, что на ней выполняется. Более того, следует стремиться к решению, которое позволяет хранить долгосрочную историю каждой метрики --- некоторые проблемы проявляются в виде долгого накопления в течение недель, которое нельзя увидеть за небольшой промежуток времени.

%Good examples for issues exposed by a long-term view include memory or process leaks, but also could be regular or irregular spikes in activities relative to the time of the day or week, which can often require having months of data to be sure about it.
Хорошие примеры проблем, которые можно обнаружить глядя на историю за долгое время --- это утечки памяти или процессов, обычные или необычные всплески активности относительно времени дня или недели, что часто требует наличие многомесячных архивов данных для укрепления уверенности в догадках.

%For these cases, using existing Erlang metrics applications is useful. Common options are:
Для этих случаев полезно использовать существующие Erlang-приложения для сбора метрик. Общепринятыми вариантами обычно являются следующие:

\begin{itemize*}
%	\item \otpapp{folsom}\footnote{\href{https://github.com/boundary/folsom}{https://github.com/boundary/folsom}} to store metrics in memory within the VM, whether global or app-specific..
	\item \otpapp{folsom}\footnote{\href{https://github.com/boundary/folsom}{https://github.com/boundary/folsom}} сохраняет метрики в памяти внутри виртуальной машины, как глобальные так и для конкретных приложений.
%	\item \otpapp{vmstats}\footnote{\href{https://github.com/ferd/vmstats}{https://github.com/ferd/vmstats}} and \otpapp{statsderl}\footnote{\href{https://github.com/lpgauth/statsderl}{https://github.com/lpgauth/statsderl}}, sending node metrics over to graphite through \app{statsd}\footnote{\href{https://github.com/etsy/statsd/}{https://github.com/etsy/statsd/}}.
	\item \otpapp{vmstats}\footnote{\href{https://github.com/ferd/vmstats}{https://github.com/ferd/vmstats}} и \otpapp{statsderl}\footnote{\href{https://github.com/lpgauth/statsderl}{https://github.com/lpgauth/statsderl}}, отправляет метрики узла на сервис graphite посредством \app{statsd}\footnote{\href{https://github.com/etsy/statsd/}{https://github.com/etsy/statsd/}}.
%	\item \otpapp{exometer}\footnote{\href{https://github.com/Feuerlabs/exometer}{https://github.com/Feuerlabs/exometer}}, a fancy-pants metrics system that can integrate with \otpapp{folsom} (among other things),  and a variety of back-ends (graphite, collectd, \app{statsd}, Riak, SNMP, etc.). It's the newest player in town
	\item \otpapp{exometer}\footnote{\href{https://github.com/Feuerlabs/exometer}{https://github.com/Feuerlabs/exometer}}, хорошо выглядящая система метрик, которая может интегрироваться с \otpapp{folsom} (и другими), и рядом серверных модулей (graphite, collectd, \app{statsd}, Riak, SNMP, и т.д.). Один из новейших проектов на рынке.
%	\item \otpapp{ehmon}\footnote{\href{https://github.com/heroku/ehmon}{https://github.com/heroku/ehmon}} for output done directly to standard output, to be grabbed later through specific agents, splunk, and so on.
	\item \otpapp{ehmon}\footnote{\href{https://github.com/heroku/ehmon}{https://github.com/heroku/ehmon}} для сбора вывода, идущего на стандартный вывод, который потом можно собрать другими специальными программами, например splunk и так далее.
%	\item custom hand-rolled solutions, generally using ETS tables and processes periodically dumping the data.\footnote{Common patterns may fit the \otpapp{ectr} application, at \href{https://github.com/heroku/ectr}{https://github.com/heroku/ectr}}
	\item Различные самодельные решения, в основном использующие таблицы ETS и процессы, которые периодически сохраняют данные на диск.\footnote{Общие шаблоны использования их могут совпадать с приложением \otpapp{ectr}, которое находится здесь \href{https://github.com/heroku/ectr}{https://github.com/heroku/ectr}}
%	\item or if you have nothing and are in trouble, a function printing stuff in a loop in a shell\footnote{The \otpapp{recon} application has the function \function{\href{http://ferd.github.io/recon/recon.html\#node\_stats\_print-2}{recon:node\_stats\_print/2}} to do this if you're in a pinch}.
	\item Если у вас ничего нет, а проблемы уже начались, то функция, печатающая данные в цикле\footnote{Приложение \otpapp{recon} имеет функцию \function{\href{http://ferd.github.io/recon/recon.html\#node\_stats\_print-2}{recon:node\_stats\_print/2}}.} поможет в трудную минуту.
\end{itemize*}

%It is generally a good idea to explore them a bit, pick one, and get a persistence layer that will let you look through your metrics over time.
В целом является хорошей идеей посвятить немного времени изучению этих инструментов, выбрать один и настроить хранение данных так, чтобы можно было изучать метрики, собранные за долгое время.


\subsection{Память}

%The memory reported by the Erlang VM in most tools will be a variant of what is reported by \expression{erlang:memory()}:
Расход памяти в виртуальной машине Erlang, показанный в большинстве инструментов, будет результатом вызова одного из вариантов команды \expression{erlang:memory()}:

\begin{VerbatimEshell}
1> erlang:memory().
[{total,13772400},
 {processes,4390232},
 {processes_used,4390112},
 {system,9382168},
 {atom,194289},
 {atom_used,173419},
 {binary,979264},
 {code,4026603},
 {ets,305920}]
\end{VerbatimEshell}

%This requires some explaining.
Это требует некоторых пояснений.

%First of all, all the values returned are in bytes, and they represent memory \emph{allocated} (memory actively used by the Erlang VM, not the memory set aside by the operating system for the Erlang VM). It will sooner or later look much smaller than what the operating system reports.
Первым делом все значения, которые возвращаются, измеряются в байтах и представляют \emph{выделенную} память (память, активно используемую виртуальной машиной, а не зарезервированную операционной системой для виртуальной машины). Рано или поздно эти цифры начнут расходиться с информацией от операционной системы и будут выглядеть меньше.

%The \expression{total} field contains the sum of the memory used for \expression{processes} and \expression{system} (which is incomplete, unless the VM is instrumented!). \expression{processes} is the memory used by Erlang processes, their stacks and heaps. \expression{system} is the rest: memory used by ETS tables, atoms in the VM, refc binaries\footnote{See Section \ref{sec:binaries}}, and some of the hidden data I mentioned was missing.
Поле \expression{total} содержит сумму памяти, которая использована для процессов (\expression{processes}) и системы (\expression{system}). Информация о памяти в системе неполная, если виртуальная машина не скомпилирована с особыми параметрами инструментации. Поле \expression{processes} --- это память, используемая Erlang-процессами, их стеками и кучами. Поле \expression{system} --- всё остальное: память ETS-таблиц, атомов в виртуальной машине, большие двоичные данные\footnote{Смотрите секцию \NamedRef{sec:binaries}}, и некоторые скрытые данные, которые, как я упоминал, могут приводить к несовпадению цифр.

%If you want the total amount of memory owned by the virtual machine, as in the amount that will trip system limits (\app{ulimit}), this value is more difficult to get from within the VM. If you want the data without calling \app{top} or \app{htop}, you have to dig down into the VM's memory allocators to find things out.\footnote{See Section \ref{subsec:erlang-memory-model}}
Если вам нужно общее количество памяти, которой владеет виртуальная машина, то число, которое может упереться в системный лимит (\app{ulimit}), это значение получить изнутри виртуальной машины немного сложнее. Если вам нужны данные без вызова внешней программы \app{top} или \app{htop}, вам придётся заглянуть внутрь аллокаторов памяти виртуальной машины.\footnote{Смотрите секцию \NamedRef{subsec:erlang-memory-model}.}

%Fortunately, recon has the function \function{recon\_alloc:memory/1} to figure it out, where the argument is:
К счастью recon имеет функцию \function{recon\_alloc:memory/1}, которая выясняет ответ на этот вопрос, и аргумент функции может быть одним из следующих значений:

\begin{itemize*}
%	\item \expression{used} reports the memory that is actively used for allocated Erlang data;
	\item \expression{used} сообщает о памяти, активно используемой для выделенных в Erlang данных.
%   	\item \expression{allocated} reports the memory that is reserved by the VM. It includes the memory used, but also the memory yet-to-be-used but still given by the OS. This is the amount you want if you're dealing with \app{ulimit} and OS-reported values.
	\item \expression{allocated} сообщает о зарезервированной в виртуальной машине памяти. Это включает использованную память, а также ещё незанятую, но уже выделенную операционной системой. Это то число, которое вам может понадобиться, если ваш узел упирается в системные ограничения, заданные посредством \app{ulimit}.
%	\item \expression{unused} reports the amount of memory reserved by the VM that is not being allocated. Equivalent to \expression{allocated - used}.
	\item \expression{unused} сообщает о количестве памяти, которая зарезервирована виртуальной машиной но ещё не выделена. Эквивалент выражения \expression{allocated - used}.
%	\item \expression{usage} returns a percentage (0.0 .. 1.0) of used over allocated memory ratios.
	\item \expression{usage} возвращает значение соотношения использованной к выделенной памяти (число от 0 до 1).
\end{itemize*}

%There are additional options available, but you'll likely only need them when investigating memory leaks in chapter \NamedRef{chap:memory-leaks}
Есть и другие опции, но вероятно вам они понадобятся лишь при чтении главы \NamedRef{chap:memory-leaks}.

\subsection{Утилизация процессора}
\label{subsec:global-cpu}

%Unfortunately for Erlang developers, CPU is very hard to profile. There are a few reasons for this:
К несчастью для Erlang-программистов, расход процессорного времени оценивать очень сложно. Этому есть ряд причин:

\begin{itemize*}
%	\item The VM does a lot of work unrelated to processes when it comes to scheduling — high scheduling work and high amounts of work done by the Erlang processes are hard to characterize.
	\item Виртуальная машина выполняет много задач, не связанных с процессами, когда дело касается планировки задач --- большие расходы на планировку и расходы процессов на выполнение их работы трудно охарактеризовать.
%	\item The VM internally uses a model based on \emph{reductions}, which represent an arbitrary number of work actions. Every function call, including BIFs, will increment a process reduction counter. After a given number of reductions, the process gets descheduled.
	\item Виртуальная машина внутри использует модель редукций (уменьшений счётчика, или \emph{reductions}), который представляет некоторое число некоторых действий. Каждый вызов функций, включая встроенные функции, изменяет этот счётчик. После заданного числа редукций процесс прекращает исполняться и планировщик передаёт управление следующему в очереди.
%	\item To avoid going to sleep when work is low, the threads that control the Erlang schedulers will do busy looping. This ensures the lowest latency possible for sudden load spikes. The VM flag \command{+sbwt none|very\_short|short|medium|long|very\_long} can be used to change this value.
	\item Чтобы избежать засыпания, когда работы недостаточно, потоки, которые контролируют планировщики задач Erlang, занимают себя пустыми циклами. Это гарантирует наилучшую возможную скорость ответа при внезапном всплеске нагрузки. Флаг виртуальной машины \command{+sbwt none|very\_short|short|medium|long|very\_long} может изменить это значение при старте.
\end{itemize*}

%These factors combine to make it fairly hard to find a good absolute measure of how busy your CPU is actually running Erlang code. It will be common for Erlang nodes in production to do a moderate amount of work and use a lot of CPU, but to actually fit a lot of work in the remaining place when the workload gets higher.
Эти факторы сочетаются и делают сложной задачей поиск абсолютной меры того, насколько ваш центральный процессор занят выполнением Erlang-кода. Обычным делом является ситуация, когда Erlang-узлы на производстве делают умеренное количество работы и используют ощутимо много процессорного времени, но способны выполнить много новой работы, используя оставшуюся свободную ёмкость, при возрастании нагрузки.

%The most accurate representation for this data is the scheduler wall time. It's an optional metric that needs to be turned on by hand on a node, and polled at regular intervals. It will reveal the time percentage a scheduler has been running processes and normal Erlang code, NIFs, BIFs, garbage collection, and so on, versus the amount of time it has spent idling or trying to schedule processes.
Самым точным представлением таких данных является время <<настенных часов>> (\emph{wall}) планировщика. Это необязательная метрика, которую следует включить на узле вручную и опрашивать с некоторой периодичностью. Она покажет отношение времени, в течение которого планировщик выполняет процессы и обычный Erlang-код, встроенные функции (NIF, BIF), сборку мусора и так далее к времени, потраченному на пустые циклы ожидания или попытки выбрать новый процесс для запуска.

%The value here represents \emph{scheduler utilization} rather than CPU utilization. The higher the ratio, the higher the workload.
Это значение представляет скорее \emph{занятость планировщика}, чем занятость центрального процессора. Чем выше это соотношение, тем больше занят планировщик.

%While the basic usage is explained in the Erlang/OTP reference manual\footnote{\href{http://www.erlang.org/doc/man/erlang.html\#statistics\_scheduler\_wall\_time}{http://www.erlang.org/doc/man/erlang.html\#statistics\_scheduler\_wall\_time}}, the value can be obtained by calling recon:
В то время, как базовый способ употребления разъясняется в документации по Erlang/OTP\footnote{\href{http://www.erlang.org/doc/man/erlang.html\#statistics\_scheduler\_wall\_time}{http://www.erlang.org/doc/man/erlang.html\#statistics\_scheduler\_wall\_time}}, эти числа можно получить, вызывая библиотеку recon:

\begin{VerbatimEshell}
1> recon:scheduler_usage(1000).
[{1,0.9919596133421669},
 {2,0.9369579039389054},
 {3,1.9294092120138725e-5},
 {4,1.2087551402238991e-5}]
\end{VerbatimEshell}

%The function \function{recon:scheduler\_usage(N)} will poll for \var{N} milliseconds (here, 1 second) and output the value of each scheduler. In this case, the VM has two very loaded schedulers (at 99.2\% and 93.7\% repectively), and two mostly unused ones at far below 1\%. Yet, a tool like \app{htop} would report something closer to this for each core:
Функция \function{recon:scheduler\_usage(N)} будет опрашивать в течение \var{N} миллисекунд (в данном случае 1 секунды) и выведет значение для каждого планировщика. В этом случае виртуальная машина имеет два очень нагруженных планировщика (занятых на уровне 99.2\% и 93.7\% соответственно) и два в основном свободных, с утилизацией сильно меньше 1\%. Однако инструмент операционной системы, такой как \app{htop} сообщит нам другие цифры:

\begin{VerbatimText}
[|||||||||||||||||||||||||     70.4%]
[|||||||                       20.6%]
[|||||||||||||||||||||||||||||100.0%]
[||||||||||||||||              40.2%]
\end{VerbatimText}

%The result being that there is a decent chunk of CPU usage that would be mostly free for scheduling actual Erlang work (assuming the schedulers are busy waiting more than trying to select tasks to run), but is being reported as busy by the OS.
Причина такого результата в том, что некоторая часть <<использованного>> процессорного времени на самом деле доступна для выполнения работы на Erlang (предполагается, что некоторые планировщики заняты пустым ожиданием, а не выбором очередной задачи для запуска), но операционная система видит это как нагрузку.

%Another interesting behaviour possible is that the scheduler usage may show a higher rate (1.0) than what the OS will report. Schedulers waiting for os resources are considered utilized as they cannot handle more work. If the OS itself is holding up on non-CPU tasks it is still possible for Erlang's schedulers not to be able to do more work and report a full ratio.
Возможно и другое интересное поведение, когда утилизация планировщика может показать значение выше, чем сообщила операционная система. Планировщики, ждущие некоторого ресурса ОС считаются занятыми, поскольку они не в состоянии обработать новые задачи. Если сама ОС блокирует некторые не связанные с процессором задачи, то вполне возможна ситуация, когда планировщики Erlang не могут выполнить больше работы и сообщают о полной загрузке.

%These behaviours may especially be important to consider when doing capacity planning, and can be better indicators of headroom than looking at CPU usage or load.
Эти шаблоны поведения могут вам пригодиться при планировании ёмкости вашей системы и могут быть более хорошими индикаторами запаса <<свободного места над головой>>, чем взгляд на загрузку или использование процессора.

%% 08:37 #erlounge: <+garazdawi> MononcQc: There is a cost when not doing work. The way it works is that when starting/stopping to do work it checks the time, but if the
%%                              scheduler has something to do the entire time then there is no overhead. So you might see a slight cpu increase if the schedulers run out of
%%                              work often, but it will (should) not affect the maximum possible throughput of the system.

\subsection{Процессы}
\label{subsec:global-procs}

%Trying to get a global view of processes is helpful when trying to assess how much work is being done in the VM in terms of \emph{tasks}. A general good practice in Erlang is to use processes for truly concurrent activities — on web servers, you will usually get one process per request or connection, and on stateful systems, you may add one process per-user — and therefore the number of processes on a node can be used as a metric for load.
Попытка получить общий вид всех процессов может оказаться полезной, когда вы пытаетесь оценить, сколько работы выполняется виртуальной машиной с точки зрения \emph{задач}. Обычной хорошей практикой в Erlang является использование процессов для истинно параллельных действий --- на веб-серверах, вы обычно можете использовать один процесс на каждый запрос или каждое подключение, на системах с полноценным состоянием, вы могли бы использовать один процесс на пользователя --- и таким образом число процессов на узле может быть метрикой текущей загрузки.

%Most tools mentioned in section \NamedRef{sec:global-view} will track them in one way or another, but if the process count needs to be done manually, calling the following expression is enough:
Большая часть инструментов, упомянутых в секции \NamedRef{sec:global-view}, будут отслеживать их так или иначе, но если вам нужно получить только их количество, то такого выражения будет достаточно:

\begin{VerbatimEshell}
1> length(processes()).
56535
\end{VerbatimEshell}

%Tracking this value over time can be extremely helpful to try and characterize load or detect process leaks, along with other metrics you may have around.
Сохранение истории этого значения в виде например, графика, может оказаться полезным чтобы попытаться охарактеризовать нагрузку или выявить утечку процессов с помощью этой и других метрик, которые будут у вас под руками.


\subsection{Порты}
\label{subsec:global-ports}

%In a manner similar to processes, \emph{Ports} should be considered. Ports are a datatype that encompasses all kinds of connections and sockets opened to the outside world: TCP sockets, UDP sockets, SCTP sockets, file descriptors, and so on.
Подобно процессам, следует обратить внимание и на \emph{порты}. Порты являются типом данных, которым представлены все виды подключений и сокетов, открытых во внешний мир: TCP-сокеты, UDP-сокеты, SCTP-сокеты, дескрипторы открытых файлов и так далее.

%There is a general function (again, similar to processes) to count them: \expression{length(erlang:ports())}. However, this function merges in all types of ports into a single entity. Instead, one can use \otpapp{recon} to get them sorted by type:
Имеется общая функция (снова-таки подобно процессам), которая их пересчитает: \expression{length(erlang:ports())}. Однако, эта функция соединяет порты всех типов в один список. Вместо этого можно использовать \otpapp{recon} для того, чтобы разобрать порты по типам:

\begin{VerbatimEshell}
1> recon:port_types().
[{"tcp_inet",21480},
 {"efile",2},
 {"udp_inet",2},
 {"0/1",1},
 {"2/2",1},
 {"inet_gethost 4 ",1}]
 \end{VerbatimEshell}

%This list contains the types and the count for each type of port. The type name is a string and is defined by the Erlang VM itself.
Этот список содержит виды и количество портов каждого вида. Имя типа --- строка, и её содержимое определяет сама виртуальная машина.

%All the \expression{*\_inet} ports are usually sockets, where the prefix is the protocol used (TCP, UDP, SCTP). The \expression{efile} type is for files, while \expression{"0/1"} and \expression{"2/2"} are file descriptors for standard I/O channels (\emph{stdin} and \emph{stdout}) and standard error channels (\emph{stderr}), respectively.
Все порты типа \expression{*\_inet} обычно являются сокетами, где приставка указывает на протокол (TCP, UDP, SCTP). Тип \expression{efile} относится к файлам, а \expression{"0/1"} и \expression{"2/2"} --- файловые дескрипторы стандартных каналов ввода-вывода (пара \emph{stdin} и \emph{stdout}) и \emph{stderr} соответственно.

%Most other types will be given names of the driver they're talking to, and will be examples of \emph{port programs}\footnote{\href{http://www.erlang.org/doc/tutorial/c\_port.html}{http://www.erlang.org/doc/tutorial/c\_port.html}} or \emph{port drivers}\footnote{\href{http://www.erlang.org/doc/tutorial/c\_portdriver.html}{http://www.erlang.org/doc/tutorial/c\_portdriver.html}}.
Большинство других типов получат имена согласно драйверу, который с ними работает, и будут являться примерами \emph{программ, работающих с портами}\footnote{Урок по портам: \href{http://www.erlang.org/doc/tutorial/c\_port.html}{http://www.erlang.org/doc/tutorial/c\_port.html}} или \emph{драйверов портов}\footnote{Урок по драйверам: \href{http://www.erlang.org/doc/tutorial/c\_portdriver.html}{http://www.erlang.org/doc/tutorial/c\_portdriver.html}}.

%Again, tracking these can be useful to assess load or usage of a system, detect leaks, and so on.
Снова-таки отслеживание этих ресурсов может пригодиться для оценки загрузки или использования системы, поиска утечек и так далее.


%\section{Digging In}
\section{Копаем поглубже}
\label{sec:digging-in}

%Whenever some 'in the large' view (or logging, maybe) has pointed you towards a potential cause for an issue you're having, it starts being interesting to dig around with a purpose. Is a process in a weird state? Maybe it needs tracing\footnote{See Chapter \NamedRef{chap:tracing}}! Tracing is great whenever you have a specific function call or input or output to watch for, but often, before getting there, a lot more digging is required.
Когда что-то в <<виде сверху>> (или в ваших файлах журналов, возможно) указало в направлении потенциальной причины имеющейся проблемы, появляется интерес копать в поисках уже с конкретной целью. Находится ли процесс в странном состоянии? Может быть, ему поможет трассировка\footnote{Смотрите главу \NamedRef{chap:tracing}}! Трассировка --- это прекрасный инструмент, когда у вас имеется некоторый вызов функции или входные или выходные данные, за полётом которых надо проследить, но часто перед тем, как они приведут нас к проблеме, требуются большие раскопки.

%Outside of memory leaks, which often need their own specific techniques and are discussed in Chapter \NamedRef{chap:memory-leaks}, the most common tasks are related to processes, and ports (file descriptors and sockets).
За пределами утечек памяти, для которых нужны свой особенный подход, и которые обсуждаются в главе \NamedRef{chap:memory-leaks}, чаще всего попадаются задачи, которые относятся к процессам и портам (файловым дескрипторам и сокетам).


\subsection{Копаем в процессы}
\label{subsec:digging-procs}

%By all means, processes are an important part of a running Erlang system. And because they're so central to everything that goes on, there's a lot to want to know about them. Fortunately, the VM makes a lot of information available, some of which is safe to use, and some of which is unsafe to use in production (because they can return data sets large enough that the amount of memory copied to the shell process and used to print it can kill the node).
Со всех сторон процессы являются важной частью работающей Erlang-системы. И поскольку они такие важные для всего, есть множество причин желать узнать о них побольше. К счастью виртуальная машина даёт очень много информации, часть из которой безопасна, и ещё часть опасна для использования на производственном сервере (поскольку возвращаемые объёмы данных могут оказаться настолько большими, что копирование их в процесс интерактивного интерпретатора и попытка распечатать на экране могут убить узел).

%All the values can be obtained by calling \expression{process\_info(Pid, Key)} or \newline \expression{process\_info(Pid, [Keys])}\footnote{In cases where processes contain sensitive information, data can be forced to be kept private by calling \expression{process\_flag(sensitive, true)}}. Here are the commonly used keys\footnote{For \emph{all} options, look at \href{http://www.erlang.org/doc/man/erlang.html\#process\_info-2}{http://www.erlang.org/doc/man/erlang.html\#process\_info-2}}:
Все значения могут быть получены с помощью функции \expression{process\_info(Pid, Ключ)} или \expression{process\_info(Pid, [СписокКлючей])}\footnote{В тех случаях, когда процессы содержат секретную информацию, данные можно скрыть с помощью вызова \expression{process\_flag(sensitive, true)} --- это ограничит печать содержимого процесса на экран.}. Вот некоторые часто используемые ключи\footnote{Для списка \emph{всех} опций загляните в документацию \href{http://www.erlang.org/doc/man/erlang.html\#process\_info-2}{http://www.erlang.org/doc/man/erlang.html\#process\_info-2}}:

\begin{description*}
	\item[Общие (meta)] \hfill
		\begin{description}		
%	\item[\expression{dictionary}] returns all the entries in the process dictionary\footnote{See \href{http://www.erlang.org/course/advanced.html\#dict}{http://www.erlang.org/course/advanced.html\#dict} and \href{http://ferd.ca/on-the-use-of-the-process-dictionary-in-erlang.html}{http://ferd.ca/on-the-use-of-the-process-dictionary-in-erlang.html}}. Generally safe to use, because people shouldn't be storing gigabytes of arbitrary data in there.
	\item[\expression{dictionary}] возвратит все записи в словаре процесса\footnote{Смотрите \href{http://www.erlang.org/course/advanced.html\#dict}{http://www.erlang.org/course/advanced.html\#dict} и \href{http://ferd.ca/on-the-use-of-the-process-dictionary-in-erlang.html}{http://ferd.ca/on-the-use-of-the-process-dictionary-in-erlang.html}}. Обычно можно спокойно использовать, поскольку людям не следует сохранять гигабайты данных в этом хранилище.
		
%	\item[\expression{group\_leader}] the group leader of a process defines where IO (files, output of \function{io:format/1-3}) goes.\footnote{See \href{http://learnyousomeerlang.com/building-otp-applications\#the-application-behaviour}{http://learnyousomeerlang.com/building-otp-applications\#the-application-behaviour} and \href{http://erlang.org/doc/apps/stdlib/io\_protocol.html}{http://erlang.org/doc/apps/stdlib/io\_protocol.html} for more details.}
	\item[\expression{group\_leader}] --- лидер группы процесса определяет, куда направляется ввод и вывод (файлы, печать на экран функцией \function{io:format/1-3})\footnote{Для подробного описания смотрите книгу \href{http://learnyousomeerlang.com/building-otp-applications\#the-application-behaviour}{http://learnyousomeerlang.com/building-otp-applications\#the-application-behaviour} и \href{http://erlang.org/doc/apps/stdlib/io\_protocol.html}{http://erlang.org/doc/apps/stdlib/io\_protocol.html}.}
			
%	\item[\expression{registered\_name}] if the process has a name (as registered with \function{erlang:register/2}), it is given here.
	\item[\expression{registered\_name}] если процесс имеет имя (зарегистрированное, например, вызовом \function{erlang:register/2}), оно будет здесь.
			
%	\item[\expression{status}] the nature of the process as seen by the scheduler. The possible values are:
		\begin{description*}
%			\item[\expression{exiting}] the process is done, but not fully cleared yet;
			\item[\expression{exiting}] процесс завершил работу но ещё не закончил очистку;
%			\item[\expression{waiting}] the process is waiting in a \expression{receive ... end};
			\item[\expression{waiting}] процесс ждёт в операторе \expression{receive ... end};
%			\item[\expression{running}] self-descriptive;
			\item[\expression{running}] очевидно из названия, процесс выполняется в данный момент;
%			\item[\expression{runnable}] ready to run, but not scheduled yet because another process is running;
			\item[\expression{runnable}] готов выполняться, но пока не получил процессорного времени, потому что другой процесс выполняется в данный момент;
%			\item[\expression{garbage\_collecting}] self-descriptive;
			\item[\expression{garbage\_collecting}] выполняется сборка мусора;
%			\item[\expression{suspended}] whenever it is suspended by a BIF, or as a back-pressure mechanism because a socket or port buffer is full. The process only becomes runnable again once the port is no longer busy.
			\item[\expression{suspended}] процесс заморожен встроенной (BIF) функцией или механизмом обратного давления сокета или драйвера порта, поскольку их буфер переполнен. Процесс сможет стать исполняемым снова, когда порт освободится для продолжения работы.
		\end{description*}
	\end{description}

	\item[Сигналы (signals)] \hfill
	\begin{description}
%		\item[\expression{links}] will show a list of all the links a process has towards other processes and also ports (sockets, file descriptors). Generally safe to call, but to be used with care on large supervisors that may return thousands and thousands of entries.
		\item[\expression{links}] покажет список всех связей, которые соединяют его с другими процессами и также портами (сокетами и дескрипторами файлов). Обычно является безопасной функцией, но будьте осторожны, поскольку на больших наблюдателях эта функция может вернуть многие тысячи элементов.
		
%		\item[\expression{monitored\_by}] gives a list of processes that are monitoring the current process (through the use of \function{erlang:monitor/2}).
		\item[\expression{monitored\_by}] даст список процессов, которые производят мониторинг текущего процесса (с помощью функции  \function{erlang:monitor/2}).
		
%		\item[\expression{monitors}] kind of the opposite of \expression{monitored\_by}; it gives a list of all the processes being monitored by the one polled here.
		\item[\expression{monitors}] опция, противоположная предыдущей  (\expression{monitored\_by}), которая даёт список всех процессов, мониторинг которых производит текущий процесс.
				
%		\item[\expression{trap\_exit}] has the value \expression{true} if the process is trapping exits, \expression{false} otherwise.
		\item[\expression{trap\_exit}] будет иметь значение \expression{true}, если процесс перехватывает сигналы выхода и превращает их в сообщения, иначе \expression{false}.
	\end{description}		
		
	\item[Местонахождение (location)] \hfill
		\begin{description}
%	\item[\expression{current\_function}] displays the current running function, as a tuple of the form \expression{\{Mod, Fun, Arity\}}.
	\item[\expression{current\_function}] выведет текущую исполняемую функцию, в виде кортежа \expression{\{Модуль, ИмяФункции, Арность\}}.

%	\item[\expression{current\_location}] displays the current location within a module, as a tuple of the form \expression{\{Mod, Fun, Arity, [\{File, FileName\}, \{line, Num\}]\}}.
	\item[\expression{current\_location}] покажет текущее положение внутри модуля, в виде кортежа \expression{\{Модуль, Функция, Арность, [\{file, ИмяФайла\}, \{line, Строка\}]\}}.
			
%	\item[\expression{current\_stacktrace}] more verbose form of the preceding option; displays the current stacktrace as a list of 'current locations'.
	\item[\expression{current\_stacktrace}] более многословный вариант предыдущей опции, который покажет текущий стек вызовов в виде списка <<текущих положений>>.
			
%	\item[\expression{initial\_call}] shows the function that the process was running when spawned, of the form \expression{\{Mod, Fun, Arity\}}. This may help identify what the process was spawned as, rather than what it's running right now.
	\item[\expression{initial\_call}] покажет функцию, с которой начал исполнение процесс при своём порождении, записывается в виде \expression{\{Модуль, Функция, Арность\}}. Это может помочь найти источник, где процесс был порождён, а не только место, где он сейчас исполняется.
\end{description}

\item[Расход памяти (memory\_used)] \hfill
	\begin{description}
%	\item[\expression{binary}] Displays the all the references to refc binaries\footnote{See Section \NamedRef{sec:binaries}} along with their size. Can be unsafe to use if a process has a lot of them allocated.
	\item[\expression{binary}] выводит все ссылки на блоки двоичных данных, считаемые по количеству ссылок (\emph{refc})\footnote{Смотрите секцию \NamedRef{sec:binaries}} вместе с их размерами. Может оказаться небезопасной функцией, если процесс владеет большим их количеством.
		
%	\item[\expression{garbage\_collection}] contains information regarding garbage collection in the process. The content is documented as 'subject to change' and should be treated as such. The information tends to contains entries such as the number of garbage collections the process has went through, options for full-sweep garbage collections, and heap sizes.
	\item[\expression{garbage\_collection}] содержит информацию относительно сборки мусора в процессе. Содержимое документировано, как <<может быть изменено в будущем>> и не должно расцениваться, как имеющее известную стабильную структуру. Информация содержит записи, такие как число сборок мусора, проведённых для данного процесса, опции для сборок мусора в режиме полных проходов (\emph{full-sweep}), и размеры куч.

%	\item[\expression{heap\_size}] A typical Erlang process contains an 'old' heap and a 'new' heap, and goes through generational garbage collection. This entry shows the process' heap size for the newest generation, and it usually includes the stack size. The value returned is in \emph{words}.
	\item[\expression{heap\_size}] обычный Erlang-процесс содержит <<старую>> и <<новую>> версии кучи, которые подвергаются сборке мусора по поколениям. Эта запись показывает размер кучи новейшего поколения, и обычно включает в себя размер стека. Возвращаемое значение измеряется в \emph{словах}, а не байтах.
	
%	\item[\expression{memory}] Returns, in \emph{bytes}, the size of the process, including the call stack, the heaps, and internal structures used by the VM that are part of a process.
	\item[\expression{memory}] возвратит, в \emph{байтах}, размер процесса, включая стек, кучи и внутренние структуры, которые использует виртуальная машина и являющиеся частью процесса.

%	\item[\expression{message\_queue\_len}] Tells you how many messages are waiting in the mailbox of a process.
	\item[\expression{message\_queue\_len}] сообщает, сколько сообщений ждут в почтовом ящике процесса.

%	\item[\expression{messages}] Returns all of the messages in a process' mailbox. This attribute is \emph{extremely} dangerous to request in production because mailboxes can hold millions of messages if you're debugging a process that managed to get locked up. \emph{Always} call for the \expression{message\_queue\_len} first to make sure it's safe to use.
	\item[\expression{messages}] возвращает все сообщения в почтовом ящике процесса. Эта опция \emph{исключительно опасна} при вызове на производственном сервере, поскольку почтовые ящики могут хранить миллионы сообщений. Если вы отлаживаете процесс, который оказался заблокирован, то \emph{всегда} сначала проверяйте длину почтового ящика  посредством \expression{message\_queue\_len}, чтобы убедиться в безопасности получения всех сообщений.

%	\item[\expression{total\_heap\_size}] Similar to \expression{heap\_size}, but also contains all other fragments of the heap, including the old one. The value returned is in \emph{words}.
	\item[\expression{total\_heap\_size}] подобно опции \expression{heap\_size}, но также включает в себя все другие фрагменты кучи, включая старое поколение. Возвращаемое значение измеряется в \emph{словах}.
	\end{description}
	
\item[Работа (work)] \hfill
	\begin{description}
%	\item[\expression{reductions}] The Erlang VM does scheduling based on \emph{reductions}, an arbitrary unit of work that allows rather portable implementations of scheduling (time-based scheduling is usually hard to make work efficiently on as many OSes as Erlang runs on). The higher the reductions, the more work, in terms of CPU and function calls, a process is doing.
	\item[\expression{reductions}] виртуальная машина выполняет планирование задач на основании числа \emph{редукций}, некоторой произвольно выбранной единицы работы, которая позволяет переносимые на разные платформы реализации планирования задач (планирование на основании времени обычно трудно заставить работать эффективно на всех операционных системах, где работает Erlang). Чем выше число редукций, тем больше работы на центральном процессоре и вызовов функций выполнил процесс.
	\end{description}
\end{description*}

%Fortunately, for all the common ones that are also safe, recon contains the \expression{recon:info/1} function to help:
К счастью для всех часто употребляемых опций, которые к тому же безопасны, recon имеет вспомогательную функцию \expression{recon:info/1}:

\begin{VerbatimEshell}
1> recon:info("<0.12.0>").
[{meta,[{registered_name,rex},
        {dictionary,[{'$ancestors',[kernel_sup,<0.10.0>]},
                     {'$initial_call',{rpc,init,1}}]},
        {group_leader,<0.9.0>},
        {status,waiting}]},
 {signals,[{links,[<0.11.0>]},
           {monitors,[]},
           {monitored_by,[]},
           {trap_exit,true}]},
 {location,[{initial_call,{proc_lib,init_p,5}},
            {current_stacktrace,[{gen_server,loop,6,
                                  [{file,"gen_server.erl"},{line,358}]},
                                 {proc_lib,init_p_do_apply,3,
                                  [{file,"proc_lib.erl"},{line,239}]}]}]},
 {memory_used,[{memory,2808},
               {message_queue_len,0},
               {heap_size,233},
               {total_heap_size,233},
               {garbage_collection,[{min_bin_vheap_size,46422},
                                    {min_heap_size,233},
                                    {fullsweep_after,65535},
                                    {minor_gcs,0}]}]},
 {work,[{reductions,35}]}]
\end{VerbatimEshell}

%For the sake of convenience, \expression{recon:info/1} will accept any pid-like first argument and handle it: literal pids, strings (\expression{"<0.12.0>"}), registered atoms, global names (\expression{\{global, Atom\}}), names registered with a third-party registry (e.g. with \otpapp{gproc}: \expression{\{via, gproc, Name\}}), or tuples (\expression{\{0,12,0\}}). The process just needs to be local to the node you're debugging.
Для удобства \expression{recon:info/1} примет первым аргументом любое значение, похожее на идентификатор процесса и обработает его: подойдут обычные pid, строки (\expression{"<0.12.0>"}), зарегистрированные атомы, глобальные имена (\expression{\{global, Атом\}}), имена, зарегистрированные в отдельном реестре (например \otpapp{gproc}: \expression{\{via, gproc, Имя\}}), или кортежи в виде (\expression{\{0,12,0\}}). Процесс всего лишь должен находиться локально на узле, который вы сейчас отлаживаете.

%If only a category of information is wanted, the category can be used directly:
Если требуются все значения в категории, можно использовать её название:

\begin{VerbatimEshell}
2> recon:info(self(), work).
{work,[{reductions,11035}]}
\end{VerbatimEshell}

%or can be used in exactly the same way as \function{process\_info/2}:
Можно использовать точно так же, как и стандартную \function{process\_info/2}:

\begin{VerbatimEshell}
3> recon:info(self(), [memory, status]).
[{memory,10600},{status,running}]
\end{VerbatimEshell}

%This latter form can be used to fetch unsafe information.
Эта вторая форма может быть использована для получения небезопасной информациию

%With all this data, it's possible to find out all we need to debug a system. The challenge then is often to figure out, between this per-process data, and the global one, which process(es) should be targeted.
Со всеми этими данными можно выяснить всё, что нам требуется для отладки системы. Сложнее всего определить, какие процессы потребуют отладки, сравнивая эти данные для каждого процесса и глобальную статистику.

%When looking for high memory usage, for example it's interesting to be able to list all of a node's processes and find the top \var{N} consumers. Using the attributes above and the \function{recon:proc\_count(Attribute, N)} function, we can get these results:
Глядя на высокий расход памяти, например, интересно было бы получить все процессы данного узла и отобрать \var{N} самых больших потребителей. Используя атрибуты, показанные выше, и функцию \function{recon:proc\_count(Атрибут, N)}, можно получить эти результаты:

\begin{VerbatimEshell}
4> recon:proc_count(memory, 3).
[{<0.26.0>,831448,
  [{current_function,{group,server_loop,3}},
   {initial_call,{group,server,3}}]},
 {<0.25.0>,372440,
  [user,
   {current_function,{group,server_loop,3}},
   {initial_call,{group,server,3}}]},
 {<0.20.0>,372312,
  [code_server,
   {current_function,{code_server,loop,1}},
   {initial_call,{erlang,apply,2}}]}]
\end{VerbatimEshell}

%Any of the attributes mentioned earlier can work, and for nodes with long-lived processes that can cause problems, it's a fairly useful function.
Любые из атрибутов, упомянутых ранее, могут сработать. Для узлов, на которых выполняются долгоживущие процессы, могущие причинить сложности, эта функция довольно полезна.

%There is however a problem when most processes are short-lived, usually too short to inspect through other tools, or when a moving window is what we need (for example, what processes are busy accumulating memory or running code \emph{right now}).
Однако имеется проблема, когда большинство процессов короткоживущие, обычно слишком короткие, чтобы их можно было рассмотреть другими инструментами, или когда нам требуется скользящий интервал (\emph{moving window}) (например, какие процессы заняты накоплением памяти или выполнением кода \emph{прямо сейчас}).

%For this use case, Recon has the \function{recon:proc\_window(Attribute, Num, Milliseconds)} function.
На этот случай recon имеет функцию \function{recon:proc\_window(Атрибут, Количество,} \function{Миллисекунды)}.

%It is important to see this function as a snapshot over a sliding window. A program's timeline during sampling might look like this:
Важно рассматривать эту функцию как <<снимок>> состояния на скользящем интервале. Время жизни программы во время взятия образцов может выглядеть так:

\begin{Verbatim}
--w---- [Образец1] ---x-------------y----- [Образец2] ---z--->
\end{Verbatim}

%The function will take two samples at an interval defined by \var{Milliseconds}.
Функция также возьмёт два образца с интервалом, заданным параметром \var{Миллисекунды}.

%Some processes will live between \var{w} and die at \var{x}, some between \var{y} and \var{z}, and some between \var{x} and \var{y}. These samples will not be too significant as they're incomplete.
Некоторые процессы будут живы после момента \var{w} и умрут в момент \var{x}, некоторые между \var{y} и \var{z}, а некоторые между \var{x} и \var{y}. Эти образцы не будут иметь большого значения, поскольку они неполны.

%If the majority of your processes run between a time interval \var{x} to \var{y} (in absolute terms), you should make sure that your sampling time is smaller than this so that for many processes, their lifetime spans the equivalent of \var{w} and \var{z}. Not doing this can skew the results: long-lived processes that have 10 times the time to accumulate data (say reductions) will look like huge consumers when they're not one.\footnote{Warning: this function depends on data gathered at two snapshots, and then building a dictionary with entries to differentiate them. This can take a heavy toll on memory when you have many tens of thousands of processes, and a little bit of time.}
Если подавляющее большинство ваших процессов исполняются в интервале времени между \var{x} и \var{y} (в абсолютном измерении), вам следует убедиться, что окно интервала сбора образцов короче этого времени, так чтобы время жизни процессов было аналогично интервалу между \var{w} и \var{z}. Если не следовать этому правилу, то результаты могут быть искажены: долгоживущие процессы, имеющие в 10 раз больше времени для накопления данных (например, редукций), будут выглядеть огромными потребителями ресурса, когда на самом деле они таковыми не являются\footnote{Внимание: эта функция зависит от данных, собранных несколькими снимками, и затем хранит их в словаре под разными ключами. Это может привести к росту расхода памяти, если у вас имеются десятки тысяч процессов и вы занимаетесь анализом в течение некоторого времени.}.

%The function, once running gives results like follows:
Функция после выполнения даст подобные следующему результаты:

\begin{VerbatimEshell}
5> recon:proc_window(reductions, 3, 500).
[{<0.46.0>,51728,
  [{current_function,{queue,in,2}},
   {initial_call,{erlang,apply,2}}]},
 {<0.49.0>,5728,
  [{current_function,{dict,new,0}},
   {initial_call,{erlang,apply,2}}]},
 {<0.43.0>,650,
  [{current_function,{timer,sleep,1}},
   {initial_call,{erlang,apply,2}}]}]
\end{VerbatimEshell}

%With these two functions, it becomes possible to hone in on a specific process that is causing issues or misbehaving.
С этими двумя функциями становится возможным рассмотреть конкретный процесс, который причиняет проблемы или ведёт себя неадекватно.


%\subsection{OTP Processes}
\subsection{OTP-процессы}

%When processes in question are OTP processes (most of the processes in a production system should definitely be OTP processes), you instantly win more tools to inspect them.
Когда процессы, которые вызывают вопросы, являются процессами OTP (большинство процессов на производстве определённо должны быть такими), то вы моментально приобретаете ещё несколько инструментов для их изучения.

%In general the \module{sys} module\footnote{\href{http://www.erlang.org/doc/man/sys.html}{http://www.erlang.org/doc/man/sys.html}} is what you want to look into. Read the documentation on it and you'll discover why it's so useful. It contains the following features for any OTP process:
В общем модуль \module{sys}\footnote{\href{http://www.erlang.org/doc/man/sys.html}{http://www.erlang.org/doc/man/sys.html}} это то, что вам потребуется. Прочтите документацию для него и вы поймёте, почему он такой полезный. Он может выдать следующую информацию для любого ОТР-процесса:

\begin{itemize*}
%	\item logging of all messages and state transitions, both to the shell or to a file, or even in an internal buffer to be queried;
	\item журналирование всех сообщений и переходов между состояниями, как в консоль, так и в файл или во внутренний буфер, который затем можно анализировать;
%	\item statistics (reductions, message counts, time, and so on);
	\item статистика (редукции, счёт числа сообщений, время и так далее);
%	\item fetching the status of a process (metadata including the state);
	\item статус процесса (метаданные, включая состояние);
%	\item fetching the state of a process (as in the \expression{\#state\{\}} record);
	\item выборка состояния процесса (содержимое той самой знаменитой записи \expression{\#state\{\}});
%	\item replacing that state
	\item изменение содержимого этого состояния;
%	\item custom debugging functions to be used as callbacks
	\item ваши собственные функции могут быть использованы в качестве функций обратного вызова.
\end{itemize*}

%It also provides functionality to suspend or resume process execution.
Также он обеспечивает возможность заморозить и продолжить исполнение процесса.

%I won't go into a lot of details about these functions, but be aware that they exist.
Я не буду углубляться в подробное описание этих функций, просто знайте, что такие возможности существуют.


\subsection{Порты}

%Similarly to processes, Erlang ports allow a lot of introspection. The info can be accessed by calling \function{erlang:port\_info(Port, Key)}, and more info is available through the \module{inet} module. Most of it has been regrouped by the \function{recon:port\_info/1-2} functions, which work using a somewhat similar interface to their process-related counterparts. 
Подобно процессам, порты в Erlang позволяют выполнять разную диагностику. Доступ к информации можно получить через функцию \function{erlang:port\_info(Порт, Ключ)}, и ещё больше можно узнать с помощью модуля \module{inet}. Большая часть этой диагностики также собрана в функциях \function{recon:port\_info/1-2}, которые работают подобно функциям анализа процессов.

\begin{description*}
\item[Общие (meta)] \hfill
\begin{description}		
%	\item[\expression{id}] internal index of a port. Of no particular use except to differentiate ports.
	\item[\expression{id}] внутренний индекс порта. Не очень полезен кроме как для того, чтобы различать порты между собой.
	
%	\item[\expression{name}] type of the port — with names such as \expression{"tcp\_inet"}, \expression{"udp\_inet"}, or \expression{"efile"}, for example.
	\item[\expression{name}] тип порта --- содержит имена, такие как \expression{"tcp\_inet"}, \expression{"udp\_inet"}, или \expression{"efile"}, для примера.
	
%	\item[\expression{os\_pid}] if the port is not an inet socket, but rather represents an external process or program, this value contains the os pid related to the said external program.
	\item[\expression{os\_pid}] если порт не является сокетом модуля inet, а представляет внешний процесс или приложение, то это значение содержит идентификатор процесса ОС этой программы.
\end{description}

\item[Сигналы (signals)] \hfill
\begin{description}		
%	\item[\expression{connected}] Each port has a controlling process in charge of it, and this process' pid is the \expression{connected} one.
	\item[\expression{connected}] каждый порт имеет контролирующий процесс, который за него отвечает, \expression{connected} возвращает идентификатор этого процесса.
	
%	\item[\expression{links}] ports can be linked with processes, much like other processes can be. The list of linked processes is contained here. Unless the process has been owned by or manually linked to a lot of processes, this should be safe to use.
	\item[\expression{links}] порты могут быть связаны с процессами, так же как и обычные процессы. Список связанных процессов содержится здесь. Если процессом не владеют или не связаны с ним вручную множество других процессов, то это значение должно быть безопасным.
	
%	\item[\expression{monitors}] ports that represent external programs can have these programs end up monitoring Erlang processes. These processes are listed here.
	\item[\expression{monitors}] порты, представляющие внешние программы, могут позволить этим программам мониторить процессы Erlang. Такие процессы перечислены здесь.
\end{description}
	
\item[Ввод-вывод (io)] \hfill
\begin{description}		
%	\item[\expression{input}] the number of bytes read from the port.
	\item[\expression{input}] число байтов, прочитанных из порта.
	
%	\item[\expression{output}] the number of bytes written to the port.
	\item[\expression{output}] число байтов, записанных в порт.
\end{description}

\item[Расход памяти (memory\_used)] \hfill
\begin{description}		
%	\item[\expression{memory}] this is the memory (in bytes) allocated by the runtime system for the port. This number tends to be small-ish and excludes space allocated by the port itself.
	\item[\expression{memory}] покажет размер памяти (в байтах), выделенной системой Erlang для этого порта. Число это обычно небольшое и не включает размер памяти, которую порт выделил для себя сам.
	
%	\item[\expression{queue\_size}] Port programs have a specific queue, called the driver queue\footnote{The driver queue is available to queue output from the emulator to the driver (data from the driver to the emulator is queued by the emulator in normal Erlang message queues). This can be useful if the driver has to wait for slow devices etc, and wants to yield back to the emulator.}. This return the size of this queue, in bytes.
	\item[\expression{queue\_size}] программы портов имеют отдельную очередь, которая называется очередью драйвера\footnote{Очередь драйвера доступна для накопления вывода из эмулятора к драйверу (данные в обратную сторону от драйвера к эмулятору накапливаются в обычных очередях сообщений Erlang). Это может пригодиться, если драйвер ждёь ответа например от медленных устройств, и хочет быстрее вернуть управление эмулятору.}. Эта опция вернёт размер этой очереди, в байтах.
\end{description}
	
\item[Зависящие от типа (type)] \hfill
\begin{description}		
%	\item[Inet Ports] Returns inet-specific data, including statistics\footnote{\href{http://www.erlang.org/doc/man/inet.html\#getstat-1}{http://www.erlang.org/doc/man/inet.html\#getstat-1}}, the local address and port number for the socket (\expression{sockname}), and the inet options used\footnote{\href{http://www.erlang.org/doc/man/inet.html\#setopts-2}{http://www.erlang.org/doc/man/inet.html\#setopts-2}}
	\item[Сетевые порты] вернёт данные по сокету, включая статистику\footnote{\href{http://www.erlang.org/doc/man/inet.html\#getstat-1}{http://www.erlang.org/doc/man/inet.html\#getstat-1}}, локальный адрес и номер порта для сокета (\expression{sockname}), и использованные опции модуля inet\footnote{\href{http://www.erlang.org/doc/man/inet.html\#setopts-2}{http://www.erlang.org/doc/man/inet.html\#setopts-2}}

%	\item[Others] currently no other form than inet ports are supported in recon, and an empty list is returned.
	\item[Прочие] в данное время другие типы портов, кроме как порты inet, не поддерживаются библиотекой recon, и поэтому вы можете увидеть здесь пустой список.
\end{description}
\end{description*}
		
%The list can be obtained as follows:
Список можно получить таким образом:

\begin{VerbatimEshell}
1> recon:port_info("#Port<0.818>").
[{meta,[{id,6544},{name,"tcp_inet"},{os_pid,undefined}]},
 {signals,[{connected,<0.56.0>},
           {links,[<0.56.0>]},
           {monitors,[]}]},
 {io,[{input,0},{output,0}]},
 {memory_used,[{memory,40},{queue_size,0}]},
 {type,[{statistics,[{recv_oct,0},
                     {recv_cnt,0},
                     {recv_max,0},
                     {recv_avg,0},
                     {recv_dvi,...},
                     {...}|...]},
        {peername,{{50,19,218,110},80}},
        {sockname,{{97,107,140,172},39337}},
        {options,[{active,true},
                  {broadcast,false},
                  {buffer,1460},
                  {delay_send,...},
                  {...}|...]}]}]
\end{VerbatimEshell}
		
%On top of this, functions to find out specific problematic ports exist the way they do for processes. The gotcha is that so far, recon only supports them for inet ports and with restricted attributes: the number of octets (bytes) sent, received, or both (\expression{send\_oct}, \expression{recv\_oct}, \expression{oct}, respectively), or the number of packets sent, received, or both (\expression{send\_cnt}, \expression{recv\_cnt}, \expression{cnt}, respectively).
Дополнительно к этому, как и для процессов, имеются функции поиска конкретных проблемных портов. На данный момент recon поддерживает их только для портов модуля inet и с ограниченным числом атрибутов: число октетов (байтов) отправлено, принято, или то и другое (\expression{send\_oct}, \expression{recv\_oct}, \expression{oct}, соответственно), или число пакетов отправлено, принято, или то и другое (\expression{send\_cnt}, \expression{recv\_cnt}, \expression{cnt}, соответственно).

%So for the cumulative total, which can help find out who is slowly but surely eating up all your bandwidth:
Итак для накопительной суммы, которая может помочь найти тех, кто медленно но уверенно съедает вашу пропускную способность сети:

\begin{VerbatimEshell}
2> recon:inet_count(oct, 3).
[{#Port<0.6821166>,15828716661,
  [{recv_oct,15828716661},{send_oct,0}]},
 {#Port<0.6757848>,15762095249,
  [{recv_oct,15762095249},{send_oct,0}]},
 {#Port<0.6718690>,15630954707,
  [{recv_oct,15630954707},{send_oct,0}]}]
\end{VerbatimEshell}

%Which suggest some ports are doing only input and eating lots of bytes. You can then use \function{recon:port\_info("\#Port<0.6821166>")} to dig in and find who owns that socket, and what is going on with it.
Это показывает нам, что некоторые порты выполняют лишь приём и потребляют очень много байтов. Затем можно использовать \function{recon:port\_info("\#Port<0.6821166>")}, чтобы вкопаться поглубже и найти, кто владеет сокетом, и что с ним происходит.

%Or in any other case, we can look at what is sending the most data within any time window\footnote{See the explanations for the \function{recon:proc\_window/3} in the preceding subsection} with the \function{recon:inet\_window(Attribute, Count, Milliseconds)} function:
Или для любого другого случая, можно посмотреть на тех, кто посылает больше всего данных в течение интервала времени\footnote{Смотрите пояснения к \function{recon:proc\_window/3} в предыдущей подсекции.} с помощью функции \function{recon:inet\_window(Атрибут, Количество, Миллисекунды)}:

\begin{VerbatimEshell}
3> recon:inet_window(send_oct, 3, 5000).
[{#Port<0.11976746>,2986216,[{send_oct,4421857688}]},
 {#Port<0.11704865>,1881957,[{send_oct,1476456967}]},
 {#Port<0.12518151>,1214051,[{send_oct,600070031}]}]
\end{VerbatimEshell}

%For this one, the value in the middle of the tuple is what \expression{send\_oct} was worth (or any chosen attribute for each call) during the specific time interval chosen (5 seconds here).
Для этого примера, значение в середине кортежа это изменение \expression{send\_oct} (или любой выбранный атрибут для каждого вызова), во время выбранного интервала времени (в данном случае 5 секунд).

%There is still some manual work involved into properly linking a misbehaving port to a process (and then possibly to a specific user or customer), but all the tools are in place. 
Нужно проделать дополнительную работу вручную, тобы установить связь между странно ведущим себя портом и процессом (и затем, вероятно, конкретным клиентом или пользователем системы), но все инструменты имеются в наличии.

%%%

\section{Упражнения}

\subsection*{\ReviewTitle{}}

\begin{enumerate}
%	\item What kind of values are reported for Erlang's memory?
	\item Какого рода значения можно получить о памяти Erlang?
%	\item What's a valuable process-related metric for a global view?
	\item Назовите ценную метрику, которую можно получить при обзоре состояния процессов издалека, в глобальном масштабе.
%	\item What's a port, and how should it be monitored globally?
	\item Что такое порт, и как следует выполнять его глобальный мониторинг?
%	\item Why can't you trust \app{top} or \app{htop} for CPU usage with Erlang systems? What's the alternative?
	\item Почему не следует доверять показаниям утилит операционной системы \app{top} или \app{htop} относительно расхода процессорного времени в Erlang-системах?
%	\item Name two types of signal-related information available for processes
	\item Назовите два вида информации о процессах, связанной с сигналами.
%	\item How can you find what code a specific process is running?
	\item Как можно узнать, какой код сейчас исполняет некоторый процесс?
%	\item What are the different kinds of memory information available for a specific process?
	\item Какие разные типы информации о памяти имеются для каждого конкретного процесса?
%	\item How can you know if a process is doing a lot of work?
	\item Как можно узнать, что процесс выполняет очень много работы?
%	\item Name a few of the values that are dangerous to fetch when inspecting processes in a production system.
	\item Назовите несколько значений, получение которых может оказаться опасным при диагностике и отладке?
%	\item What are some features provided to OTP processes through the sys module?
	\item Какие дополнительные возможности доступны через модуль sys для ОТР-процессов?
%	\item What kind of values are available when inspecting inet ports?
	\item Какие значения можно получить при диагностике интернет сокетов (портов модуля inets)?
%	\item How can you find the type of a port (Files, TCP, UDP)?
	\item Как можно узнать тип порта (файловый, ТСР- или UDP-сокет)?
\end{enumerate}

\subsection*{\OpenEndedTitle{}}

\begin{enumerate}
%	\item Why do you want a long time window available on global metrics?
	\item Почему в глобальных метриках для вас очень полезно иметь историю значений за долгое время?
%	\item Which would be more appropriate between \function{recon:proc\_count/2} and \function{recon:proc\_window/3} to find issues with:
	\item Какая из функций \function{recon:proc\_count/2} и \function{recon:proc\_window/3} больше подходит для поиска следующих проблем:
		\begin{enumerate*}
%			\item Reductions \item Memory \item Message queue length
			\item Количество редукций \item Память \item Длина очереди сообщений
		\end{enumerate*}
%	\item How can you find information about who is the supervisor of a given process?
	\item Как можно выяснить, какой процесс является наблюдателем для некоторого процесса?
%	\item When should you use \function{recon:inet\_count/2}? \function{recon:inet\_window/3}?
	\item Когда вам следует использовать \function{recon:inet\_count/2}? \function{recon:inet\_window/3}?
%	\item What could explain the difference in memory reported by the operating system and the memory functions in Erlang?
	\item Чем можно объяснить разницу в сообщаемом расходе памяти между операционной системой и внутренними функциями диагностики Erlang?
%	\item Why is it that Erlang can sometimes look very busy even when it isn't?
	\item Почему Erlang-узел иногда выглядит очень занятым снаружи, когда на самом деле он ничего не делает?
%	\item How can you find what proportion of processes on a node are ready to run, but can't be scheduled right away?
	\item Как можно узнать пропорцию числа процессов на узле, которые готовы к работе, но не могут немедленно получить от планировщика процессорное время?
\end{enumerate}

\subsection*{\HandsOnTitle{}}

%Using the code at
Используя код, который находится по адресу
\href{https://github.com/ferd/recon\_demo}{https://github.com/ferd/recon\_demo}
ответьте на вопросы:

\begin{enumerate}
%	\item What's the system memory?
	\item Что такое память системы?
%	\item Is the node using a lot of CPU resources?
	\item Использует ли узел очень много ресурсов процессора?
%	\item Is any process mailbox overflowing?
	\item Переполняется ли почтовый ящик какого-то из процессов?
%	\item Which chatty process (\module{council\_member}) takes the most memory?
	\item Какой из разговорчивых процессов (\module{council\_member}) занимает больше всего памяти?
%	\item Which chatty process is eating the most CPU?
	\item Какой из разговорчивых процессов потребляет больше всего ресурсов процессора?
%	\item Which chatty process is consuming the most bandwidth?
	\item Какой из разговорчивых процессов потребляет больше всего ресурсов сети?
%	\item Which chatty process sends the most messages over TCP? The least?
	\item Какой из разговорчивых процессов посылает больше всего сообщений по протоколу ТСР? А какой меньше всего?
%	\item Can you find out if a specific process tends to hold multiple connections or file descriptors open at the same time on a node?
	\item Можете ли вы найти такой процесс, который удерживает множество подключений или открытых дескрипторов файлов на данном узле?
%	\item Can you find out which function is being called by the most processes at once on the node right now?
	\item Можете ли вы найти, какая функция вызывается наибольшим количеством процессов одновременно в данный момент на этом узле?
\end{enumerate}

%%%
%%%
%%%

%%% Cognitive (Global)
%%
%% Knowledge: recall facts, terms, basic concepts
%% 
%% - What kind of values are reported for Erlang's memory?
%% - What's a valuable process-related metric for a global view?
%% - What's a port, and how should it be monitored?
%% - Why can't you trust 'top' or 'htop' for CPU usage? What's the alternative?
%% - Name two types of signal-related information available for processes
%% - How can you find what code a specific process is running?
%% - What are the different kinds of memory information available for a specific process?
%% - How can you know if a process is doing a lot of work?
%% - Name a few of the values that are dangerous to fetch when inspecting processes.
%% - What are some features provided to OTP processes through the sys module?
%% - What kind of values are available when inspecting inet ports?
%% - How can you find the type of a port (Files, TCP, UDP)?
%%
%% Comprehension: organizing, comparing, translating, interpreting, giving descriptions, and stating the main ideas
%%
%% - Why do you want a long time window available on global metrics?
%% - Why can tracking counts of things such as file descriptors be useful?
%% - Which would be more appropriate between recon:proc_count/2 and recon:proc_window to find issues with:
%%   a) reductions  b)  memory  c)  message queue length
%% - How can you find information about who is the supervisor of a given process?
%% - When should you use recon:inet_count/2? recon:inet_window/3?
%%
%% Application: Solve problems in new situations by applying acquired knowledge, facts, techniques and rules in a different way
%%
%% - What could explain the difference in memory reported by the operating system and the memory functions in Erlang?
%% - Why is it that Erlang can sometimes look very busy even when it isn't?
%%
%%   Using https://github.com/ferd/recon_demo (recon is part of the release):
%% - What's the system memory?
%% - Is the node's CPU loaded?
%% - Is any process mailbox overflowing?
%% - Is the node using any UDP ports at all?
%%
%% Analysis: break down info, make inferences, find evidence
%%
%% - What could point to your node's schedulers doing a lot of busy looping for no reason?
%%
%%   Using https://github.com/ferd/recon_demo (recon is part of the release):
%% - Which chatty process takes the most memory?
%% - Which chatty process is eating the most CPU?
%% - Which chatty process is consuming the most bandwidth?
%% - Which chatty process sends the most messages over TCP? The least?
%%
%% Synthesis: Compile information together in a different way by combining elements in a new pattern or proposing alternative solutions
%%
%% - The number of processes on web-server node keeps increasing all the time, rarely going down, while the number of file descriptors remains mostly stable. What could explain this? Is it a problem?
%% - Can you find out if a specific process tends to hold multiple connections or file descriptors open at the same time on a node?
%% - Can you find out which function is being called by the most processes at once on any given node right now?
%% - What proportion of processes on a node are ready to run, but can't be scheduled right away?
%% - Are most connections on a node mostly unidirectional (sending or receiving more data) or symmetric (well-balanced input and output)?
%%
%% Evaluation: Present and defend opinions by making judgments about information
%%
%% - What other values would it be worth tracking over time for a global view? They can be application-specific.
%% - Do you think it's ever worth replacing the state of processes while they're running (through the sys module) ?
%% - Could you use the port info in order to bill specific customers? If not, what else could you do with it?
